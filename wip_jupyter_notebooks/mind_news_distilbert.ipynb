{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mind_news_recommend_distilbert.ipynb","provenance":[],"collapsed_sections":["2Sb0MwFY2Ok3","dyXb7Cip72Sg"],"authorship_tag":"ABX9TyPLJl8sxrY9wb8/L15sD1RR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"S8gt9AflX62E"},"source":["# Mount google drive"]},{"cell_type":"code","metadata":{"id":"_PpUmu2lLtmy"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahhY7LxKL9q1"},"source":["!ls drive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQA4sDwILwyC"},"source":["cd /content/drive/MyDrive/Colab Notebooks/recommendation_systems"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmEW-UaZr3lc"},"source":["! ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Sb0MwFY2Ok3"},"source":["# Install transformer"]},{"cell_type":"markdown","metadata":{"id":"Mndy-25P2Vi8"},"source":["https://huggingface.co/transformers/installation.html"]},{"cell_type":"code","metadata":{"id":"7ZacutfM2Rn9"},"source":["! pip install transformers\n","# ! pip install sentencepiece\n","# ! pip install Torchtext==0.04"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAZ7pc7Z-9o-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jVWH9wGE3-I9"},"source":["# Import modules"]},{"cell_type":"code","metadata":{"id":"1QUJrcaB4Adt"},"source":["import os\n","import re\n","import time\n","import random\n","from glob import glob\n","import zipfile\n","import pickle\n","from pprint import pprint\n","import csv\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly\n","import plotly.express as px\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, plot_confusion_matrix, confusion_matrix\n","from sklearn.metrics import roc_curve, roc_auc_score\n","from wordcloud import WordCloud\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torchtext\n","from transformers import AutoModel, AutoTokenizer\n","import torch.optim as optim\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('max_colwidth', None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dyXb7Cip72Sg"},"source":["## set random seed"]},{"cell_type":"code","metadata":{"id":"c6GrCLqH7570"},"source":["def set_random_seed(seeds):\n","    random.seed(seeds)\n","    os.environ['PYTHONHASHSEED'] = str(seeds)\n","    np.random.seed(seeds)\n","    torch.manual_seed(seeds)\n","    torch.use_deterministic_algorithms(True)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seeds)\n","    return\n","set_random_seed(999)    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6V6c1mH8Y_ec"},"source":["# Load and process data\n","\n","https://msnews.github.io/"]},{"cell_type":"markdown","metadata":{"id":"ztxJ5HQWYbs9"},"source":["## load data"]},{"cell_type":"code","metadata":{"id":"nnXxkQRmrsd7"},"source":["# train and validate (instead of test) datasets are used here.\n","data_path_train = \"/content/drive/MyDrive/Colab Notebooks/recommendation_systems/mind_dataset/MINDlarge_train/\"\n","data_path_test = \"/content/drive/MyDrive/Colab Notebooks/recommendation_systems/mind_dataset/MINDlarge_dev/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ze-AVNOJQv1n"},"source":["# filename_train_all = data_path_train + \"news_click_df_all.csv\"\n","filename_train_all = data_path_train + \"news_click_df_select.csv\"\n","filename_train = data_path_train + \"news_click_df.csv\"\n","data_df_train = pd.read_csv(filename_train_all)\n","print (data_df_train[\"click_prob_flag\"].value_counts())\n","print (data_df_train[\"category_flag\"].value_counts())\n","data_df_train.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h0oHtLtLbgZH"},"source":["# filename_test_all = data_path_test + \"news_click_df_all.csv\"\n","filename_test_all = data_path_test + \"news_click_df_select.csv\"\n","filename_test = data_path_test + \"news_click_df.csv\"\n","data_df_test = pd.read_csv(filename_test_all)\n","print (data_df_test[\"click_prob_flag\"].value_counts())\n","print (data_df_test[\"category_flag\"].value_counts())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4KEj7BO5Br6"},"source":["## select data"]},{"cell_type":"code","metadata":{"id":"YdiBhQ8-03kF"},"source":["data_df_train[\"text\"] = data_df_train[\"title\"] #+ \". \" + data_df_train[\"abstract\"]\n","data_df_test[\"text\"] = data_df_test[\"title\"] #+ \". \" + data_df_test[\"abstract\"]\n","data_df_train[\"label\"] = data_df_train[\"click_prob_flag\"] # category_flag # click_prob_flag\n","data_df_test[\"label\"] = data_df_test[\"click_prob_flag\"]\n","\n","select_col = [\"text\",\"label\"]\n","num_classes = len(data_df_train[\"label\"].unique())\n","\n","def select_data(data_df_train, select_col, filename_train):\n","    select_data_df_train = data_df_train[select_col].tail(int(len(data_df_train)/10))\n","    select_data_df_train.to_csv(filename_train, index=False)\n","    print (select_data_df_train[\"label\"].value_counts())\n","    return select_data_df_train\n","\n","select_data_df_train = select_data(data_df_train, select_col, filename_train)\n","select_data_df_test = select_data(data_df_test, select_col, filename_test)\n","select_data_df_train.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7V3k0DZI1UEa"},"source":["# DistilBERT"]},{"cell_type":"markdown","metadata":{"id":"I-qt1SXG133x"},"source":["document: https://huggingface.co/transformers/model_doc/distilbert.html\n","\n","pretrained model: https://huggingface.co/transformers/pretrained_models.html\n","\n","japanese: https://github.com/BandaiNamcoResearchInc/DistilBERT-base-jp/blob/main/docs/GUIDE.md"]},{"cell_type":"markdown","metadata":{"id":"nb-auLdlolqG"},"source":["## Tokenization"]},{"cell_type":"code","metadata":{"id":"-O_zRsmX1VM7"},"source":["# #### English\n","select_pretrained_model = \"distilbert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(select_pretrained_model)\n","distilbert_model = AutoModel.from_pretrained(select_pretrained_model)\n","\n","# #### Japanese\n","# tokenizer_jap = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n","# distilbert_jap_model = AutoModel.from_pretrained(\"bandainamco-mirai/distilbert-base-japanese\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AflCwrd91pXn"},"source":["tokenizer.tokenize(\"I have a new GPU!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cKK1bYYf3ma1"},"source":["print(distilbert_model)\n","# print(distilbert_jap_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7hpV86EKnzeq"},"source":["## Process train/test data"]},{"cell_type":"markdown","metadata":{"id":"Wuh33gG5dhlq"},"source":["Torchtext is used for processing data.\n","\n","Mainly, three steps: \n","1. create Field object\n","2. create dataset\n","3. separate batches\n","\n","migration tutorial: \n","https://colab.research.google.com/github/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb#scrollTo=ez2lT2QO0sNj\n","\n","https://github.com/mmg10/pytorch_text_new/blob/main/LSTM_text.ipynb"]},{"cell_type":"code","metadata":{"id":"oZcy49bICPnk"},"source":["# tokenizer.encode(data_df_train[\"title\"].values[0], return_tensors='pt')[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FhXdrZh4EhIE"},"source":["# train_encodings = tokenizer(data_df_train[\"title\"].values.tolist(), truncation=True, padding=True)\n","# train_encodings"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6MJ1BqB2jOmx"},"source":["## old version format using legacy"]},{"cell_type":"code","metadata":{"id":"f3Ebl-hPp5zG"},"source":["# create Field object\n","def text_tokenizer(text):\n","    return tokenizer.encode(text, return_tensors='pt')[0]\n","\n","TEXT = torchtext.legacy.data.Field(sequential=True, tokenize=text_tokenizer, use_vocab=False, lower=False,\n","                            include_lengths=True, batch_first=True, pad_token=0, unk_token=0, eos_token=0)\n","LABEL = torchtext.legacy.data.Field(sequential=False, use_vocab=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AS4INqmf6-v8"},"source":["# read csv file and create dataset\n","train_dataset = torchtext.legacy.data.TabularDataset(path=filename_train, format='csv', skip_header=True,\n","                            fields=[('text', TEXT), ('label', LABEL)])\n","test_dataset = torchtext.legacy.data.TabularDataset(path=filename_test, format='csv', skip_header=True,\n","                            fields=[('text', TEXT), ('label', LABEL)])\n","\n","# check data\n","for train in train_dataset:\n","    print (train.text, train.label)\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2IdDGZP6-2u"},"source":["# seperate batches\n","BATCH_SIZE = 256 #32\n","train_iter, test_iter = torchtext.legacy.data.Iterator.splits((train_dataset, test_dataset), batch_sizes=(BATCH_SIZE, BATCH_SIZE), repeat=False, sort=False)\n","print (len(train_iter))\n","\n","# check data\n","for train in train_iter:\n","    print (train.text, train.label)\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hX4x4zJPjUCm"},"source":["## new recent version"]},{"cell_type":"code","metadata":{"id":"NjjOhIag3D4S"},"source":["print(torch.__version__)\n","print(torchtext.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"axnbQ8nZ9eTB"},"source":["import collections\n","# from torchtext.experimental.functional import sequential_transforms, vocab_func, totensor\n","# from torchtext.experimental.datasets.text_classification import TextClassificationDataset\n","\n","def get_data_from_csv(filename_train):\n","    with open(filename_train, mode='r') as csv_file:\n","        csv_reader = csv.reader(csv_file)\n","        next(csv_reader)\n","        data = [tuple(line) for line in csv_reader]\n","    return data\n","\n","class Tokenizer:\n","    def __init__(self, tokenize_fn = 'basic_english', lower = True, max_length = None):\n","        \n","        self.tokenize_fn = torchtext.data.utils.get_tokenizer(tokenize_fn)\n","        self.lower = lower\n","        self.max_length = max_length\n","        \n","    def tokenize(self, s):\n","        \n","        tokens = self.tokenize_fn(s)\n","        \n","        if self.lower:\n","            tokens = [token.lower() for token in tokens]\n","            \n","        if self.max_length is not None:\n","            tokens = tokens[:self.max_length]\n","            \n","        return tokens\n","\n","def build_vocab_from_data(data, tokenizer, **vocab_kwarg):\n","    \n","    token_freqs = collections.Counter()\n","    \n","    for text, label  in data:\n","        tokens = tokenizer.tokenize(text)\n","        token_freqs.update(tokens)\n","        \n","    vocab = torchtext.vocab.Vocab(token_freqs, **vocab_kwarg)\n","    \n","    return vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cU8h0qVC9Tdn"},"source":["def data_to_dataset(data, tokenizer, vocab):\n","    \n","    data = [(text, label) for (text, label) in data]\n","    \n","    text_transform = sequential_transforms(tokenizer.tokenize,\n","                                                  vocab_func(vocab),\n","                                                  totensor(dtype=torch.long)\n","                                          )\n","    label_transform = sequential_transforms(lambda x: 1 if x =='1' else (0 if x =='0' else x),\n","                                                  totensor(dtype=torch.long)\n","                                          )\n","    \n","    \n","    transforms = (text_transform, label_transform)\n","    \n","    dataset = TextClassificationDataset(data, vocab, transforms)\n","    \n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHEz_J9GkUah"},"source":["# get data\n","train_data = get_data_from_csv(filename_train)\n","print(train_data[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uYrqIOrDjo1S"},"source":["# # tokenizer\n","max_length=2500\n","tokenizer = Tokenizer(max_length=max_length)\n","\n","# build vocab\n","max_size = 25000\n","# vocab = build_vocab_from_data(train_data, tokenizer, max_size = max_size)\n","vocab = build_vocab_from_data(train_data, tokenizer)\n","vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kasweq4n9ThL"},"source":["# convert data to dataset\n","train_dataset = data_to_dataset(train_data, tokenizer, vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mm9P5zL39TkW"},"source":["train_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bi28JvMh9Tmb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"580sDSca6FiJ"},"source":["## Set up model"]},{"cell_type":"code","metadata":{"id":"JbjLb6ipTdb6"},"source":["# Creating the customised model, by adding a dense layer on top of distilbert to get the final output for the model. \n","class DistilBERTClassifier(torch.nn.Module):\n","    def __init__(self):\n","        super(DistilBERTClassifier, self).__init__()\n","        self.distil_bert = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n","        # self.pre_classifier = torch.nn.Linear(768, 768)\n","        # self.dropout = torch.nn.Dropout(0.1)\n","        self.classifier = torch.nn.Linear(768, num_classes)\n","\n","        # weight initialisation\n","        nn.init.normal_(self.classifier.weight, std=0.02)\n","        nn.init.normal_(self.classifier.bias, 0)\n","\n","    def forward(self, input_ids):\n","        output_1 = self.distil_bert(input_ids=input_ids)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        # pooler = self.pre_classifier(pooler)\n","        # pooler = torch.nn.Tanh()(pooler)\n","        # pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return F.log_softmax(output, dim=1) # output # F.log_softmax(output)\n","\n","distil_classifier = DistilBERTClassifier()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lE_DKarG6BSg"},"source":["## fine tuning"]},{"cell_type":"code","metadata":{"id":"QhBm2qdD4Utj"},"source":["# Turn OFF all paramters\n","for param in distil_classifier.parameters():\n","    param.requires_grad = False\n","\n","# Turn ON the last layer parameter\n","# .transfomer.layer[-1] for DistilBERT or .encoder.layer[-1] for BERT-base\n","for param in distil_classifier.distil_bert.transformer.layer[-1].parameters():\n","    param.requires_grad = True\n","\n","# Turn ON the classification part\n","for param in distil_classifier.classifier.parameters():\n","    param.requires_grad = True\n","\n","# Small lr value for pretrained layer and bigger value for the last layer\n","optimizer = optim.Adam([\n","    {'params': distil_classifier.distil_bert.transformer.layer[-1].parameters(), 'lr': 5e-5},\n","    {'params': distil_classifier.classifier.parameters(), 'lr': 1e-4}\n","])\n","\n","loss_function = nn.NLLLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ila33Ii06Dpy"},"source":["## training"]},{"cell_type":"code","metadata":{"id":"GH5Yj_aA5VX8"},"source":["# Set up GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# Pass model to GPU\n","distil_classifier.to(device)\n","losses = []\n","\n","start = time.time()\n","# Set up epoch \n","for epoch in range(50):\n","    all_loss = 0\n","    for idx, batch in enumerate(train_iter):\n","        # print (\"iter: \", idx)\n","        batch_loss = 0\n","        distil_classifier.zero_grad()\n","        input_ids = batch.text[0].to(device)\n","        label_ids = batch.label.to(device)\n","        out = distil_classifier(input_ids)\n","        batch_loss = loss_function(out, label_ids)\n","        batch_loss.backward()\n","        optimizer.step()\n","        all_loss += batch_loss.item()\n","    print(\"epoch: \", epoch, \"\\t\" , \"loss: \", all_loss)\n","\n","end = time.time()\n","print (\"time : \", end - start)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N0KCpsvk6LpU"},"source":["## predict"]},{"cell_type":"code","metadata":{"id":"BoUMYjcw4Non"},"source":["def plot_confusion_matrix_heatmap(true_labels, predicted_labels, title):\n","    # get_metrics\n","    print('Accuracy:', metrics.accuracy_score(true_labels, predicted_labels))\n","    print('Precision:', metrics.precision_score(true_labels, predicted_labels, average='weighted'))\n","    print('Recall:', metrics.recall_score(true_labels, predicted_labels, average='weighted'))\n","    print('F1 Score:', metrics.f1_score(true_labels, predicted_labels,average='weighted'))\n","\n","    # confusion matrix\n","    labels = list(set(true_labels))\n","    cm = confusion_matrix(true_labels, predicted_labels, labels=labels)\n","    cm_labeled = pd.DataFrame(cm, columns=labels, index=labels)\n","    sns.heatmap(cm_labeled, annot=True, cmap='Greens', fmt='g')\n","    plt.title(title)\n","    return\n","\n","def plot_roc_auc(true_labels, predicted_labels, title_name):\n","    true_labels = np.array(true_labels)\n","    predicted_labels = np.array(predicted_labels)\n","    fpr, tpr, _ = roc_curve(true_labels,  predicted_labels)\n","    print ('roc_curve-fpr:', fpr)\n","    print ('roc_curve-tpr:', tpr)\n","    auc = roc_auc_score(true_labels, predicted_labels, average=None)\n","    print ('roc_auc_score-auc:', auc)\n","    fig = plt.figure(figsize=(6,4))\n","    plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n","    plt.legend(loc=4)\n","    title_name = \"roc and auc \" + str(title_name)\n","    plt.titile(title_name)\n","    plt.show()\n","    plt.close(fig)\n","    return\n","\n","def predict_texts_distilbert(batch_iter, title_name=None):\n","    answer = []\n","    prediction = []\n","    with torch.no_grad():\n","        for batch in batch_iter:\n","\n","            text_tensor = batch.text[0].to(device)\n","            label_tensor = batch.label.to(device)\n","\n","            score = distil_classifier(text_tensor)\n","            _, pred = torch.max(score, 1)\n","\n","            prediction += list(pred.cpu().numpy())\n","            answer += list(label_tensor.cpu().numpy())\n","\n","    # print classification report\n","    print(classification_report(prediction, answer))\n","    print(\"predicted label: \", set(prediction))\n","\n","    # plot confusion matrix\n","    plot_confusion_matrix_heatmap(answer, prediction, \"confusion matrix {}\".format(title_name))\n","    try:\n","        plot_roc_auc(answer, prediction, title_name)\n","    except:\n","        pass    \n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q2K3DCaC4mFE"},"source":["predict_texts_distilbert(test_iter, \"test\")  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XmAvgyyl5oya"},"source":["predict_texts_distilbert(train_iter, \"train\")  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ea_OB7Er6PU1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vpo7J2bg3ZEF"},"source":["# Knowledge distillation"]},{"cell_type":"code","metadata":{"id":"M6zHNY6D-HuO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_QHG8Q6-HyR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwLP93lS6PXi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KR_KKuiDVoN-"},"source":["# Unmount and flush google drive"]},{"cell_type":"code","metadata":{"id":"F3N2KCmog-Jl"},"source":["# from google.colab import drive\n","# drive.flush_and_unmount()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2nPp--NF29d"},"source":[""],"execution_count":null,"outputs":[]}]}